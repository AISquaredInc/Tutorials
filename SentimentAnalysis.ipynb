{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis in the Browser\n",
    "\n",
    "In this notebook, we will show how to create a `.air` file to perform sentiment analysis in the browser using a neural network.  To do this, we will utilize the IMDB Movie Reviews dataset to build the initial model and then package the model using the `aisquared` Python SDK."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies\n",
    "\n",
    "For this notebook, the following dependencies are required:\n",
    "\n",
    "- `aisquared`\n",
    "\n",
    "This package is available on [pypi](https://pypi.org) via `pip`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import aisquared"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Creation\n",
    "\n",
    "Now that the required packages have been installed and imported, it is time to create the sentiment analysis model.  To do this, we have to first load and preprocess the data, create the model, and then package the model in the `.air` format.  The following cells will go through an in-depth explanation of each of the steps in this process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('IMDB Dataset.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data and tokenize\n",
    "\n",
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(10000, oov_token = 1)\n",
    "tokenizer.fit_on_texts(df.review)\n",
    "vocab = tokenizer.word_index\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(df.review)\n",
    "sequences = tf.keras.preprocessing.sequence.pad_sequences(sequences, 256, padding = 'pre', truncating = 'post')\n",
    "\n",
    "labels = df.sentiment.apply(lambda x : {'positive' : 0, 'negative' : 1}[x]).values\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(sequences, labels, train_size = 0.7)\n",
    "del vocab[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model\n",
    "\n",
    "input_layer = tf.keras.layers.Input(sequences.shape[1:])\n",
    "embedding_layer = tf.keras.layers.Embedding(\n",
    "    10000,\n",
    "    4\n",
    ")(input_layer)\n",
    "x = tf.keras.layers.Flatten()(embedding_layer)\n",
    "for _ in range(5):\n",
    "    x = tf.keras.layers.Dense(1000, activation = 'relu')(x)\n",
    "output_layer = tf.keras.layers.Dense(1, activation = 'sigmoid')(x)\n",
    "\n",
    "model = tf.keras.models.Model(input_layer, output_layer)\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "\n",
    "# Train the model with the sparsification callback\n",
    "model.fit(\n",
    "    x_train,\n",
    "    y_train.reshape(-1,1),\n",
    "    epochs = 20,\n",
    "    batch_size = 512,\n",
    "    validation_split = 0.2,\n",
    "    verbose = 2,\n",
    "    callbacks = None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check model performance\n",
    "preds = (model.predict(x_test) >= 0.5).astype(int)\n",
    "print('Model Performance on Test Data:')\n",
    "print('\\n')\n",
    "print(confusion_matrix(y_test, preds))\n",
    "print(classification_report(y_test, preds))\n",
    "\n",
    "# Save the model\n",
    "model.save('SentimentClassifier.h5')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Package the Model\n",
    "\n",
    "Now that the model has been created, we can package the model into a single `.air` file that enables integration into the browser.\n",
    "\n",
    "To perform this packaging, we will be utilizing the `aisquared` package `DocumentPredictor` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "harvester = aisquared.config.harvesting.InputHarvester()\n",
    "\n",
    "preprocessor = aisquared.config.preprocessing.text.TextPreprocesser(\n",
    "    [\n",
    "        aisquared.config.preprocessing.text.RemoveCharacters(),\n",
    "        aisquared.config.preprocessing.text.ConvertToCase(lowercase = True),\n",
    "        aisquared.config.preprocessing.text.Tokenize(),\n",
    "        aisquared.config.preprocessing.text.ConvertToVocabulary(vocabulary = vocab, oov_character = 1, start_character = 0),\n",
    "        aisquared.config.preprocessing.text.PadSequences(length = 256, pad_location = 'pre', truncate_location = 'post')\n",
    "    ]\n",
    ")   \n",
    "analytic = aisquared.config.analytic.LocalModel('SentimentClassifier.h5', 'text')\n",
    "\n",
    "postprocessor = aisquared.config.postprocessing.BinaryClassification(['positive', 'negative'], 0.5)\n",
    "\n",
    "renderer = aisquared.config.rendering.DocumentRendering(include_probability = True)\n",
    "\n",
    "feedback = aisquared.config.feedback.BinaryFeedback(['positive', 'negative'])\n",
    "\n",
    "aisquared.config.ModelConfiguration(\n",
    "    'SentimentClassifier',\n",
    "    harvester,\n",
    "    preprocessor,\n",
    "    analytic,\n",
    "    postprocessor,\n",
    "    renderer,\n",
    "    feedback).compile(dtype = 'float16')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0671325c08d22fc44ce2e58aedbf8efae69ce5eb9c1911bbe321ecb24080d883"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
