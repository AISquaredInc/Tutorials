{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis in the Browser\n",
    "\n",
    "In this notebook, we will show how to create a `.air` file to perform sentiment analysis in the browser using a neural network.  To do this, we will utilize the IMDB Movie Reviews dataset to build the initial model and then package the model using the `aisquared` Python SDK."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies\n",
    "\n",
    "For this notebook, the following dependencies are required:\n",
    "\n",
    "- `aisquared`\n",
    "\n",
    "This package is available on [pypi](https://pypi.org) via `pip`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jwrenn4/miniforge3/lib/python3.9/site-packages/jax/_src/lib/__init__.py:33: UserWarning: JAX on Mac ARM machines is experimental and minimally tested. Please see https://github.com/google/jax/issues/5501 in the event of problems.\n",
      "  warnings.warn(\"JAX on Mac ARM machines is experimental and minimally tested. \"\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import aisquared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Creation\n",
    "\n",
    "Now that the required packages have been installed and imported, it is time to create the sentiment analysis model.  To do this, we have to first load and preprocess the data, create the model, and then package the model in the `.air` format.  The following cells will go through an in-depth explanation of each of the steps in this process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('IMDB Dataset.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data and tokenize\n",
    "\n",
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(10000, oov_token = 1)\n",
    "tokenizer.fit_on_texts(df.review)\n",
    "vocab = tokenizer.word_index\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(df.review)\n",
    "sequences = tf.keras.preprocessing.sequence.pad_sequences(sequences, 256, padding = 'pre', truncating = 'post')\n",
    "\n",
    "labels = df.sentiment.apply(lambda x : {'positive' : 0, 'negative' : 1}[x]).values\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(sequences, labels, train_size = 0.7)\n",
    "del vocab[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n",
      "\n",
      "systemMemory: 16.00 GB\n",
      "maxCacheSize: 5.33 GB\n",
      "\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 256)]             0         \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 256, 4)            40000     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1024)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1000)              1025000   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1000)              1001000   \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1000)              1001000   \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1000)              1001000   \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1000)              1001000   \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 1001      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,070,001\n",
      "Trainable params: 5,070,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create the model\n",
    "\n",
    "input_layer = tf.keras.layers.Input(sequences.shape[1:])\n",
    "embedding_layer = tf.keras.layers.Embedding(\n",
    "    10000,\n",
    "    4\n",
    ")(input_layer)\n",
    "x = tf.keras.layers.Flatten()(embedding_layer)\n",
    "for _ in range(5):\n",
    "    x = tf.keras.layers.Dense(1000, activation = 'relu')(x)\n",
    "output_layer = tf.keras.layers.Dense(1, activation = 'sigmoid')(x)\n",
    "\n",
    "model = tf.keras.models.Model(input_layer, output_layer)\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-22 15:16:31.018770: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/55 - 9s - loss: 0.6739 - accuracy: 0.5537 - val_loss: 0.5550 - val_accuracy: 0.7250 - 9s/epoch - 171ms/step\n",
      "Epoch 2/20\n",
      "55/55 - 9s - loss: 0.3667 - accuracy: 0.8403 - val_loss: 0.3416 - val_accuracy: 0.8570 - 9s/epoch - 172ms/step\n",
      "Epoch 3/20\n",
      "55/55 - 9s - loss: 0.1798 - accuracy: 0.9331 - val_loss: 0.4031 - val_accuracy: 0.8500 - 9s/epoch - 173ms/step\n",
      "Epoch 4/20\n",
      "55/55 - 9s - loss: 0.0590 - accuracy: 0.9804 - val_loss: 0.6060 - val_accuracy: 0.8404 - 9s/epoch - 157ms/step\n",
      "Epoch 5/20\n",
      "55/55 - 8s - loss: 0.0242 - accuracy: 0.9919 - val_loss: 0.8298 - val_accuracy: 0.8396 - 8s/epoch - 137ms/step\n",
      "Epoch 6/20\n",
      "55/55 - 7s - loss: 0.0156 - accuracy: 0.9949 - val_loss: 0.8656 - val_accuracy: 0.8316 - 7s/epoch - 120ms/step\n",
      "Epoch 7/20\n",
      "55/55 - 7s - loss: 0.0174 - accuracy: 0.9940 - val_loss: 0.9225 - val_accuracy: 0.8370 - 7s/epoch - 123ms/step\n",
      "Epoch 8/20\n",
      "55/55 - 6s - loss: 0.0115 - accuracy: 0.9959 - val_loss: 1.0702 - val_accuracy: 0.8400 - 6s/epoch - 111ms/step\n",
      "Epoch 9/20\n",
      "55/55 - 5s - loss: 0.0072 - accuracy: 0.9977 - val_loss: 1.1584 - val_accuracy: 0.8397 - 5s/epoch - 94ms/step\n",
      "Epoch 10/20\n",
      "55/55 - 5s - loss: 0.0074 - accuracy: 0.9974 - val_loss: 1.1677 - val_accuracy: 0.8420 - 5s/epoch - 96ms/step\n",
      "Epoch 11/20\n",
      "55/55 - 5s - loss: 0.0069 - accuracy: 0.9975 - val_loss: 1.2599 - val_accuracy: 0.8383 - 5s/epoch - 89ms/step\n",
      "Epoch 12/20\n",
      "55/55 - 5s - loss: 0.0058 - accuracy: 0.9979 - val_loss: 1.2869 - val_accuracy: 0.8390 - 5s/epoch - 84ms/step\n",
      "Epoch 13/20\n",
      "55/55 - 4s - loss: 0.0072 - accuracy: 0.9973 - val_loss: 1.3914 - val_accuracy: 0.8421 - 4s/epoch - 79ms/step\n",
      "Epoch 14/20\n",
      "55/55 - 5s - loss: 0.0041 - accuracy: 0.9986 - val_loss: 1.4283 - val_accuracy: 0.8393 - 5s/epoch - 86ms/step\n",
      "Epoch 15/20\n",
      "55/55 - 5s - loss: 0.0012 - accuracy: 0.9996 - val_loss: 1.6167 - val_accuracy: 0.8363 - 5s/epoch - 88ms/step\n",
      "Epoch 16/20\n",
      "55/55 - 4s - loss: 0.0047 - accuracy: 0.9982 - val_loss: 1.4782 - val_accuracy: 0.8389 - 4s/epoch - 77ms/step\n",
      "Epoch 17/20\n",
      "55/55 - 5s - loss: 0.0053 - accuracy: 0.9982 - val_loss: 1.3718 - val_accuracy: 0.8421 - 5s/epoch - 83ms/step\n",
      "Epoch 18/20\n",
      "55/55 - 4s - loss: 0.0033 - accuracy: 0.9992 - val_loss: 1.3300 - val_accuracy: 0.8333 - 4s/epoch - 82ms/step\n",
      "Epoch 19/20\n",
      "55/55 - 5s - loss: 0.0052 - accuracy: 0.9981 - val_loss: 1.4157 - val_accuracy: 0.8401 - 5s/epoch - 90ms/step\n",
      "Epoch 20/20\n",
      "55/55 - 5s - loss: 0.0056 - accuracy: 0.9982 - val_loss: 1.4416 - val_accuracy: 0.8429 - 5s/epoch - 83ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x157a3d5b0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compile the model\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "\n",
    "# Train the model with the sparsification callback\n",
    "model.fit(\n",
    "    x_train,\n",
    "    y_train.reshape(-1,1),\n",
    "    epochs = 20,\n",
    "    batch_size = 512,\n",
    "    validation_split = 0.2,\n",
    "    verbose = 2,\n",
    "    callbacks = None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance on Test Data:\n",
      "\n",
      "\n",
      "[[6436 1011]\n",
      " [1188 6365]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.86      0.85      7447\n",
      "           1       0.86      0.84      0.85      7553\n",
      "\n",
      "    accuracy                           0.85     15000\n",
      "   macro avg       0.85      0.85      0.85     15000\n",
      "weighted avg       0.85      0.85      0.85     15000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check model performance\n",
    "preds = (model.predict(x_test) >= 0.5).astype(int)\n",
    "print('Model Performance on Test Data:')\n",
    "print('\\n')\n",
    "print(confusion_matrix(y_test, preds))\n",
    "print(classification_report(y_test, preds))\n",
    "\n",
    "# Save the model\n",
    "model.save('SentimentClassifier.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Package the Model\n",
    "\n",
    "Now that the model has been created, we can package the model into a single `.air` file that enables integration into the browser.\n",
    "\n",
    "To perform this packaging, we will be utilizing the `aisquared` package `DocumentPredictor` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "harvester = aisquared.config.harvesting.InputHarvester()\n",
    "\n",
    "preprocessor = aisquared.config.preprocessing.text.TextPreprocessor(\n",
    "    [\n",
    "        aisquared.config.preprocessing.text.RemoveCharacters(),\n",
    "        aisquared.config.preprocessing.text.ConvertToCase(lowercase = True),\n",
    "        aisquared.config.preprocessing.text.Tokenize(),\n",
    "        aisquared.config.preprocessing.text.ConvertToVocabulary(vocabulary = vocab, oov_character = 1, start_character = 0),\n",
    "        aisquared.config.preprocessing.text.PadSequences(length = 256, pad_location = 'pre', truncate_location = 'post')\n",
    "    ]\n",
    ")   \n",
    "analytic = aisquared.config.analytic.LocalModel('SentimentClassifier.h5', 'text')\n",
    "\n",
    "postprocessor = aisquared.config.postprocessing.BinaryClassification(['positive', 'negative'], 0.5)\n",
    "\n",
    "renderer = aisquared.config.rendering.DocumentRendering(include_probability = True)\n",
    "\n",
    "feedback = aisquared.config.feedback.BinaryFeedback(['positive', 'negative'])\n",
    "\n",
    "aisquared.config.ModelConfiguration(\n",
    "    'SentimentClassifier',\n",
    "    harvester,\n",
    "    preprocessor,\n",
    "    analytic,\n",
    "    postprocessor,\n",
    "    renderer,\n",
    "    feedback).compile(dtype = 'float16')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0671325c08d22fc44ce2e58aedbf8efae69ce5eb9c1911bbe321ecb24080d883"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
