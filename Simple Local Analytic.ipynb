{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9eab911",
   "metadata": {},
   "source": [
    "# Simple AIR File Example Using Local Analytic\n",
    "\n",
    "In this notebook, we intend to get the user up to speed regarding using the `aisquared` Python package to create a `.air` file using a simple use case.  This use case will be what we have called a \"Local Analytic\", which involves creating a lookup table that matches words to results.\n",
    "\n",
    "In this notebook, we will create a `.air` file that will allow the user to identify the word 'the' on a webpage and augment the user's browsing experience with some additional context around the identified word.  We will show end-to-end how to create this integration and compile it into a `.air` file.  Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffcda09a",
   "metadata": {},
   "source": [
    "## Installing and Importing `aisquared`\n",
    "\n",
    "First, let's make sure the `aisquared` package is installed, and then we will import it.  We will also import the `json` package, which we will use to store the analytic as a JSON file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351565f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the aisquared package\n",
    "! pip install aisquared\n",
    "\n",
    "# Import the required packages\n",
    "import aisquared\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2b8173",
   "metadata": {},
   "source": [
    "## Create our analytic\n",
    "\n",
    "Before we create the `.air` file, we need to save the analytic that will be run when the word is harvested. To do this, we just need to map the word we are looking for to a result using a dictionary, then save the dictionary to a JSON file.  The following cell takes care of that for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44542613",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('analytic.json', 'w') as f:\n",
    "    json.dump({'the' : 'This is the most common word in the English language!'}, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2487cea",
   "metadata": {},
   "source": [
    "## Defining the Integration Steps\n",
    "\n",
    "Now that our analytic is saved, let's define how the integration is going to take place.  We want to harvest any instance of the word \"the\" from the webpage, then take those instances of the word and run them against the analytic we just saved, and finally render the results in the browser as a clickable underline n each instance of the word \"the\" that was found.  To do this, we are going to use:\n",
    "\n",
    "1. A `TextHarvester` to harvest the word \"the\" using a regex\n",
    "2. A `LocalAnalytic` to point to the analytic we want to run\n",
    "3. A `WordRenderer` to render the results\n",
    "\n",
    "Finally, we are going to combine these steps in a `ModelConfiguration` object and compile it into a `.air` file!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce2658a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the harvester, which will look for the word 'the'\n",
    "harvester = aisquared.config.harvesting.TextHarvester(how = 'regex', regex = 'the')\n",
    "\n",
    "# Create the analytic\n",
    "analytic = aisquared.config.analytic.LocalAnalytic('analytic.json', input_type = 'text')\n",
    "\n",
    "# Create the rendering step\n",
    "renderer = aisquared.config.rendering.WordRendering(badge_shape = 'underline')\n",
    "\n",
    "# Combine all the steps in the ModelConfiguration object\n",
    "aisquared.config.ModelConfiguration(\n",
    "    name='LocalAnalytic',\n",
    "    harvesting_steps=harvester,\n",
    "    analytic=analytic,\n",
    "    rendering_steps=renderer\n",
    ").compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c058c31f",
   "metadata": {},
   "source": [
    "## `.air` File Created!\n",
    "\n",
    "Now that the last cell was run, we now have a file called `LocalAnalytic.air` stored in the current directory!  Let's take a look at the files we have in the directory currently and check!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8776596e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0dce99d",
   "metadata": {},
   "source": [
    "## Using the `.air` File\n",
    "\n",
    "Now that we have that `.air` file, we can upload it into the platform and start using it.  Go ahead and take a few minutes and start playing around with it!\n",
    "\n",
    "Once you get comfortable, try seeing if you can modify the code here to provide different functionality.  Here are some ideas:\n",
    "\n",
    "1. Can we build a harvester that harvests the word \"the\", regardless of letters being uppercase or lowercase?\n",
    "2. Can we build a harvester that not only harvests the word \"the\", but also harvests other words?\n",
    "    1. Be sure to change the analytic to accommodate these other words!\n",
    "3. Can we change the way the rendering occurs? Maybe instead of a blue underline, we can make it a purple circle, for example?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "ce06f28078c5ee89615bc93f96b77cd60d44a9e1412956783996ce9d49602585"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
